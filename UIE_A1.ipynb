{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing, decomposition, manifold\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (38000 samples)\n",
      "test set (8190 samples)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "data_train = pickle.load(open(\"./data/data-train.pkl\", 'rb'))\n",
    "print(\"training set (%i samples)\" % data_train['rgb'].shape[0])\n",
    "data_test = pickle.load(open(\"./data/data-test.pkl\", 'rb'))\n",
    "print(\"test set (%i samples)\" % data_test['rgb'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot helper\n",
    "\n",
    "def plot(imgs):\n",
    "    # make sure input is a list\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "        \n",
    "    plt.figure()\n",
    "    for i in range(len(imgs)):\n",
    "        plt.subplot(1, len(imgs), i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-3a6d4fb0245e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-3a6d4fb0245e>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    proc_train = {id=[], pid=[], seg=[]}\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# crop and scale\n",
    "\n",
    "proc_train = {id, pid, seg, rgb, dep, mask2, mask3, label}\n",
    "\n",
    "for i in range(10):\n",
    "    sample = data_train['segmentation'][i][:, :, 0]\n",
    "    \n",
    "    top = np.min(np.nonzero(np.any(sample, axis=1)))\n",
    "\n",
    "    bottom = 120\n",
    "    if not np.any(sample[119, :]):\n",
    "        bottom = np.max(np.nonzero(np.any(sample, axis=1)))\n",
    "        bottom = top+int((bottom-top)*0.85)\n",
    "    \n",
    "    height = bottom-top\n",
    "    width = int((bottom-top)*0.75)\n",
    "    factor = 120/height\n",
    "    \n",
    "    colsum = np.sum(sample, axis=0)\n",
    "    \n",
    "    left = np.min(np.nonzero(colsum))\n",
    "    right = np.max(np.nonzero(colsum))\n",
    "    \n",
    "    cumsum = np.cumsum(colsum[left:right])\n",
    "    \n",
    "    avg = left+(np.abs(cumsum-np.average(cumsum))).argmin()\n",
    "    \n",
    "    left = 45+avg-int(45/factor)\n",
    "    right = 45+avg+int(45/factor)\n",
    "    \n",
    "    seg_tmp = data_train['segmentation'][i].copy()\n",
    "    seg_tmp = np.lib.pad(seg_tmp, ((0, 0), (45, 45), (0, 0)), 'constant', constant_values=0)\n",
    "    \n",
    "    rgb_tmp = data_train['rgb'][i].copy()\n",
    "    rgb_tmp = np.lib.pad(rgb_tmp, ((0, 0), (45, 45), (0, 0)), 'edge')\n",
    "    \n",
    "    dep_tmp = data_train['depth'][i].copy()\n",
    "    dep_tmp = np.lib.pad(dep_tmp, ((0, 0), (45, 45)), 'edge')\n",
    "    \n",
    "    seg = cv2.resize(seg_tmp[top:bottom, left:right, :] ,(90, 120), interpolation=cv2.INTER_CUBIC)\n",
    "    rgb = cv2.resize(rgb_tmp[top:bottom, left:right, :] ,(90, 120), interpolation=cv2.INTER_CUBIC)\n",
    "    dep = cv2.resize(dep_tmp[top:bottom, left:right] ,(90, 120), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "#     plot([seg, data_train['segmentation'][i]])\n",
    "    \n",
    "    seg_map2 = seg[:,:,0]>200\n",
    "    seg_map = np.tile(seg[:,:,0]>200, (3,1,1)).transpose((1,2,0))\n",
    "    seg_map = np.tile(seg[:,:,0]>200, (3,1,1)).transpose((1,2,0))\n",
    "    \n",
    "    img = seg_map2*dep\n",
    "    \n",
    "    orientations=8\n",
    "    pixels_per_cell=(16,16)\n",
    "    cells_per_block=(4,4)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "    hog_features, hog = feature.hog(img, orientations, pixels_per_cell, cells_per_block, visualise=True)\n",
    "    \n",
    "    plot([seg_map2*dep, hog])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   7   8   8   8   9  11  10   8  10   9   5 250 248 245 241 241 241\n",
      "  245   5   5 244 240 240 240 240 240 240 240 240 240 251 246 241 240 226\n",
      "  215 213 212 211 212 212 212 213 213 215 215 200 202 208 207 207 207 208\n",
      "  208 206 198 239 245 243 241 241 241 241 241 242 242 242 243 243 243 242\n",
      "  242 243 242 243 242 253   5 244 243 243 243 244 246 251  11  12  11   8]\n",
      " [  5   8   8   8   9  11  12  12  11  12  12  12  11  12  10   0 246 242\n",
      "  249  12   5 241 240 240 240 240 240 240 240 242 255   9 246 240 241 209\n",
      "  203 213 212 211 212 213 213 214 214 215 216 208 208 208 207 207 207 207\n",
      "  207 208 198 227 241 241 241 241 241 241 241 242 242 242 242 242 242 242\n",
      "  242 242 242 242 242 251   8 246 243 246 252 255   5  10  15  14  12   8]\n",
      " [253   9   9   9  10  11  12  12  11  12  12  12  12  12  13  12   7 254\n",
      "    3  13   9 244 240 240 240 240 240 240 240 245   9  11 249 240 240 181\n",
      "  163 212 212 211 212 213 213 214 215 214 218 212 226 215 208 207 207 208\n",
      "  208 208 203 206 238 241 241 241 241 241 241 242 242 242 242 242 243 243\n",
      "  242 242 242 242 242 246   4 255   4  10  15  16  15  15  15  14  12   8]\n",
      " [248  10   9   9  10  11  12  12  12  12  12  12  12  12  13  13  13  13\n",
      "   12  12  11 250 240 240 240 240 240 240 240 247  10   4 242 240 241 223\n",
      "  200 213 212 212 213 213 213 214 214 203 236 238 240 238 185 168 204 208\n",
      "  208 208 207 201 218 240 241 241 241 241 241 242 242 243 243 244 252 251\n",
      "  252   0   0   0   1   6  12  14  14  14  15  15  15  15  15  14  12   8]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAAxCAYAAAAhtuk7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABJpJREFUeJzt3MtvG1UUx/E7Hs/4VSeN08oCNSFCMYsiHkJiUQHdIVH+\nBDYI+FNYsOMvQPwl3aGKx6IS0IJUaKmaljaQlKZOGr+HBdLM/G4VP4gbV0ffz+oe3bFnPDM+mZw5\nniBJEgcAsKWw6A0AAMwfyR0ADCK5A4BBJHcAMIjkDgAGkdwBwCCSOwAYRHIHAINI7gBgUHFRK/76\nxjvy09jzpXvpuBwMZ3qvyI3Scb0wkrmu9wPcgyT7yLVgIHO9RP/WbQ9PSXy5/Wo63h+WZG6vX5F4\nt1ubsNWZ1dKBxB+fvXLksl9tX5R4pzP9ep6VC6t/SHy3syLxdqcucW8YpuMbW02ZCx/ofi3kD5Ee\nWlcYBhKPwhl+bT3msmY04VuxdMtbPsq2o6cf1QUzbFISjJ/P74vSQ33jlY/uSnyu9kjig0GcjjvD\naPqNmqA4w3e16H03xxmMxl935t/LX9Zfjz//buNmOn6rclvm/O9XbxS6acUF3ReVsJ+Oz5X/kbnP\nVn7Q1wZ68Hu5Jwc89E7IN9e3Jpwp/+HKHQAMIrkDgEEkdwAwaGE1941oR+JZ6uyRV3zN19n92lXs\nVadKyeDIZZ3TOuZq2JZ4s/Htka9tj/S13xy+LPGVvVY63u1WZe5MvC/x+Thb7y9eEfdxv+wWoVrs\nSfzB2evp+L3K7zL3Zed9ifM1dueci8PsWJd/088TP9b1HjaP8dTSMZcuyQyXNf6yncZUJc+ZTarP\nj7sXcOv+GYkra/0jllycSXX0eb3XpPW0h9k51wifyFy+Tu6c1tyXo47MbVb/knilqPfOXokfpOO1\nop7YzVDv0fUTzX/77vjHjyt3ADCI5A4ABi2sLHP1cEPiS6euTf3aOJi+pWqeni7jZBoF/Tv5YU3b\nA/Otnt8/2ZS5l+K/JY5ctp5mqCWbJe9fw53hybRCLse63nwpxm8/PR3pv7pb7rTE+TLN2mX9fO67\nnyS8/fmFmbf1/8iXXvzTa1TSeslAq2quv95Nx34rZ/xIz5lxpZdJrZCyDTVduPqj/pvfbup21OOu\ne96Na5WcZ0kn36r7Z21Z5t5e0u/terSbjlu5sXPOrRd1n0eBlh+11KLLngSu3AHAIJI7ABhEcgcA\ngxZWc7/TbUgc17N6m/8YgHkaVzefp3zd3DnnWsWstam19KvM9b0WzHwTVL2gcxtVrfud1OMHaqG2\nQubve1zrrcrczX1ty/PlWyF//lRrw403vBp7/lTwa+H+4waOcdrk6+zV+3rsKpe05a1c1MdWlMIs\n7r6oX6nCF7ovSle1bfTeJ9kjLQYzdLn6df/IayG9c/0FiVuvb6Xj/P5/liY9bsD/uf5r9ey+VGek\nj0goF7Q1sBntTb0dkddmvRFl97ha0aHMXSxr+7OKx8w93c64aFy5A4BBJHcAMIjkDgAGBUlyjJ93\nAwCeS1y5A4BBJHcAMIjkDgAGkdwBwCCSOwAYRHIHAINI7gBgEMkdAAwiuQOAQSR3ADCI5A4ABpHc\nAcAgkjsAGERyBwCDSO4AYBDJHQAMIrkDgEEkdwAwiOQOAAaR3AHAIJI7ABhEcgcAg0juAGDQv7Ji\nDY7GNe4FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f989079ddd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize depth\n",
    "print(data_train['depth'][0][28:32, :]-159)\n",
    "plot(data_train['depth'][0][28:32, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
