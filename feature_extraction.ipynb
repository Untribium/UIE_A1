{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "from skimage import feature\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# helpers\n",
    "\n",
    "# plot images, list are dislayed in subplots\n",
    "def plot(imgs, title=None):\n",
    "    # make sure input is a list\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    \n",
    "    plt.figure()\n",
    "        \n",
    "    for i in range(len(imgs)):\n",
    "        if(title is not None): \n",
    "            plt.suptitle(title)\n",
    "        plt.subplot(1, len(imgs), i+1)\n",
    "        plt.axis(\"off\")\n",
    "        # fix channels for rgb\n",
    "        if len(imgs[i].shape) > 2:\n",
    "            plt.imshow(imgs[i][:,:,[2,1,0]])\n",
    "        else:\n",
    "            plt.imshow(imgs[i])\n",
    "        \n",
    "\n",
    "# create empty list of given size\n",
    "def empty(size):\n",
    "    return [None]*size\n",
    "\n",
    "\n",
    "def empty_dict(chunk, n_features):\n",
    "    n_samples = chunk['n_samples']\n",
    "    \n",
    "    new_dict = {\n",
    "        'n_samples':  n_samples,\n",
    "        'n_features': n_features,\n",
    "        'values':     np.zeros((n_samples, n_features)),\n",
    "        'label':      np.zeros(n_samples),\n",
    "        'valid':      np.zeros(n_samples),\n",
    "        'weight':     np.zeros(n_samples),\n",
    "    }\n",
    "    \n",
    "    new_dict['label' ][:] = chunk['label' ][:]\n",
    "    new_dict['valid' ][:] = chunk['valid' ][:]\n",
    "    new_dict['weight'][:] = chunk['weight'][:]\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "# load data set\n",
    "def load_chunk(set_name, chunk_nr):\n",
    "    \n",
    "    path = './data_pp/%s_%i.pkl' % (set_name, chunk_nr)\n",
    "    \n",
    "    chunk = pickle.load(open(path, 'rb'))\n",
    "    \n",
    "    print('load_chunk: loaded %i samples (from %s)' % (chunk['n_samples'], path))\n",
    "    \n",
    "    return chunk\n",
    "    \n",
    "# dump feature set\n",
    "def dump_chunk(set_name, chunk_nr, feature_name, features):\n",
    "    \n",
    "    # set NaNs to 0\n",
    "    vals = features['values']\n",
    "    vals[np.isnan(vals)] = 0\n",
    "    \n",
    "    path = './features/%s_%i-%s.pkl' % (set_name, chunk_nr, feature_name)\n",
    "    \n",
    "    pickle.dump(features, open(path, 'wb'))\n",
    "    \n",
    "    print('dump_chunk: dumped %i samples (to %s)' % (chunk['n_samples'], path))\n",
    "\n",
    "\n",
    "def blockshaped(a, block_size):\n",
    "    (n_rows, n_cols) = block_size\n",
    "    h, w = a.shape\n",
    "    return (a.reshape(h//n_rows, n_rows, -1, n_cols).swapaxes(1,2).reshape(-1, n_rows, n_cols))\n",
    "    \n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hog_features(chunk, img_type=None):\n",
    "    \n",
    "    # hog params\n",
    "    orientations=8\n",
    "    pixels_per_cell=(20,20)\n",
    "    cells_per_block=(4,4)\n",
    "    visualize=False\n",
    "    \n",
    "    n_values = 1152\n",
    "    \n",
    "    # init container\n",
    "    features = empty_dict(chunk, 7*n_values)\n",
    "    \n",
    "    for i in range(chunk['n_samples']):\n",
    "        \n",
    "        if not (i+1)%2000:\n",
    "            print('hog_features: %i' % (i+1))\n",
    "        \n",
    "        if not chunk['valid'][i]:\n",
    "            continue\n",
    "        \n",
    "        # feature container\n",
    "        vals = features['values'][i, :]\n",
    "        \n",
    "        # grayscale\n",
    "        gs = cv2.cvtColor(chunk['rgb'][i], cv2.COLOR_RGB2GRAY)\n",
    "        vals[0*n_values:1*n_values] = feature.hog(gs, orientations, pixels_per_cell, cells_per_block, visualize)\n",
    "        \n",
    "        # red, green, blue channels\n",
    "        rc,gc,bc = cv2.split(chunk['rgb'][i])\n",
    "        vals[1*n_values:2*n_values] = feature.hog(rc, orientations, pixels_per_cell, cells_per_block, visualize)\n",
    "        vals[2*n_values:3*n_values] = feature.hog(gc, orientations, pixels_per_cell, cells_per_block, visualize)\n",
    "        vals[3*n_values:4*n_values] = feature.hog(bc, orientations, pixels_per_cell, cells_per_block, visualize)\n",
    "\n",
    "        # depth\n",
    "        dm = chunk['dep'][i]\n",
    "        vals[4*n_values:5*n_values] = feature.hog(dm, orientations, pixels_per_cell, cells_per_block, visualize)\n",
    "        \n",
    "        # segmentation\n",
    "        sm = chunk['seg'][i][:, :, 0]\n",
    "        vals[5*n_values:6*n_values] = feature.hog(sm, orientations, pixels_per_cell, cells_per_block, visualize)\n",
    "        \n",
    "        # depth (cutoff)\n",
    "        dep = chunk['dep'][i]\n",
    "        \n",
    "        cut = 127\n",
    "        while (dep<cut).sum() > 750:\n",
    "            cut -= 1\n",
    "\n",
    "        mask = np.zeros((126,126))\n",
    "\n",
    "        for x in range(0,7):\n",
    "            for y in range(0,7):\n",
    "                mask[x:126-(6-x),y:126-(6-y)] += dep<cut\n",
    "\n",
    "        mask = mask[3:123,3:123]\n",
    "        mask = mask*(mask>24)\n",
    "            \n",
    "        vals[6*n_values:7*n_values] = feature.hog(dep*mask, orientations, pixels_per_cell, cells_per_block, visualize)\n",
    "        \n",
    "    return features\n",
    "    \n",
    "\n",
    "def sift_features(chunk, img_type):\n",
    "    \n",
    "    # sift params\n",
    "    step_size = 20\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # init container\n",
    "    features = empty_dict(chunk, 30*128)\n",
    "    \n",
    "    for i in range(chunk['n_samples']):\n",
    "        \n",
    "        if not (i+1)%2000:\n",
    "            print('sift_features (%s): %i' % (img_type, i+1))\n",
    "        \n",
    "        if not chunk['valid'][i]:\n",
    "            continue\n",
    "        \n",
    "        img = chunk[img_type][i]\n",
    "    \n",
    "        grid = [cv2.KeyPoint(x, y, step_size)\n",
    "                for y in range(10, img.shape[0]-10, step_size)\n",
    "                    for x in range(0, img.shape[1], step_size)]\n",
    "        \n",
    "        features['values'][i, :] = sift.compute(img, grid)[1].ravel()\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "def diff_features(chunk, img_type):\n",
    "    \n",
    "    # diff params\n",
    "    block_size = (3, 3)\n",
    "    \n",
    "    # init container\n",
    "    features = empty_dict(chunk, (120*60)//(block_size[0]*block_size[1]))\n",
    "    \n",
    "    for i in range(chunk['n_samples']):\n",
    "        \n",
    "        if not (i+1)%2000:\n",
    "            print('diff_features (%s): %i' % (img_type, i+1))\n",
    "        \n",
    "        if not chunk['valid'][i]:\n",
    "            continue\n",
    "        \n",
    "        img = chunk[img_type][i]\n",
    "        \n",
    "        l = img[:, :60].T\n",
    "        r = np.flip(img[:, 60:], 1).T\n",
    "        \n",
    "        l_sums = [a.sum() for a in blockshaped(l, block_size)]\n",
    "        r_sums = [a.sum() for a in blockshaped(r, block_size)]\n",
    "        \n",
    "        features['values'][i, :] = np.array(l_sums) - np.array(r_sums)\n",
    "        \n",
    "    return features\n",
    "        \n",
    "\n",
    "extractors = {\n",
    "    'hog': hog_features,\n",
    "    'sift': sift_features,\n",
    "    'diff': diff_features,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_name = 'test'\n",
    "chunk_nr = 0\n",
    "extractor = 'diff'\n",
    "img_type = 'dep'\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_chunk: loaded 8190 samples (from ./data_pp/test_0.pkl)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "chunk = load_chunk(set_name, chunk_nr)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_features (dep): 2000\n",
      "diff_features (dep): 4000\n",
      "diff_features (dep): 6000\n",
      "diff_features (dep): 8000\n",
      "(8190, 800)\n",
      "0:00:22.086539\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "features = extractors[extractor](chunk, img_type)\n",
    "print(features['values'].shape)\n",
    "\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump_chunk: dumped 8190 samples (to ./features/test_0-diff_dep_0.pkl)\n"
     ]
    }
   ],
   "source": [
    "dump_chunk(set_name, chunk_nr, '%s_%s_%i' % (extractor, img_type, iteration), features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
